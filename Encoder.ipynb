{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oJHf0rC41rwL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask = None):\n",
        "  d_k = q.size()[-1]\n",
        "  scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
        "  print(f\"scaled.size() : {scaled.size()}\")\n",
        "  if mask is not None:\n",
        "    print(f\"-- ADDING MASK of shape {mask.size()} --\")\n",
        "    scaled += mask\n",
        "  attention = F.softmax(scaled, dim = -1)\n",
        "  values = torch.matmul(attention, v)\n",
        "  return values, attention\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_model // self.num_heads\n",
        "    self.qkv_layer = nn.Linear(d_model, 3 * d_model)\n",
        "    self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "  def forward(self, x, mask = None):\n",
        "    batch_size, max_sequence_length, d_model = x.size()\n",
        "    print(f\"x.size(): {x.size()}\")\n",
        "    qkv = self.qkv_layer(x)\n",
        "    print(f\"qkv.size(): {qkv.size()}\")\n",
        "    qkv = qkv.reshape(batch_size, max_sequence_length, self.num_heads, 3 * self.head_dim)\n",
        "    print(f\"qkv.size(): {qkv.size()}\")\n",
        "    qkv = qkv.permute(0, 2, 1, 3)\n",
        "    print(f\"qkv.size(): {qkv.size()}\")\n",
        "    q, k, v = qkv.chunk(3, dim = -1)\n",
        "    print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
        "    values, attention = scaled_dot_product_attention(q, k, v, mask)\n",
        "    print(f\"values.size(): {values.size()}, attention.size(): {attention.size()} \")\n",
        "    values = values.reshape(batch_size, max_sequence_length, self.num_heads * self.head_dim)\n",
        "    print(f\"values.size(): {values.size()}\")\n",
        "    out = self.linear_layer(values)\n",
        "    print(f\"out.size(): {out.size()}\")\n",
        "    return out\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "  def __init__(self, parameters_shape, eps = 1e-5):\n",
        "    super().__init__()\n",
        "    self.parameters_shape = parameters_shape\n",
        "    self.eps = eps\n",
        "    self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
        "    self.beta = nn.Parameter(torch.zeros(parameters_shape))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
        "    mean = inputs.mean(dim = dims, keepdim = True)\n",
        "    print(f\"Mean ({mean.size()}): \\n{mean}\")\n",
        "    var = ((inputs - mean) ** 2).mean(dim = dims, keepdim = True)\n",
        "    std = (var + self.eps).sqrt()\n",
        "    print(f\"Standard Deviation ({std.size()}): \\n{std}\")\n",
        "    y = (inputs - mean) / std\n",
        "    print(f\"y ({y.size()}): \\n{y}\")\n",
        "    out = self.gamma + y + self.beta\n",
        "    print(f\"self.gamma: {self.gamma.size()}, self.beta: {self.beta.size()}\")\n",
        "    print(f\"Out: {out.size()}\")\n",
        "    return out\n",
        "\n",
        "class PositionWiseFeedForward(nn.Module):\n",
        "  def __init__(self, d_model, hidden, drop_prob = 0.1):\n",
        "    super(PositionWiseFeedForward, self).__init__()\n",
        "    self.linear1 = nn.Linear(d_model, hidden)\n",
        "    self.linear2 = nn.Linear(hidden, d_model)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(p = drop_prob)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    print(f\"x after first linear layer: {x.size()}\")\n",
        "    x = self.relu(x)\n",
        "    print(f\"x after activation: {x.size()}\")\n",
        "    x = self.dropout(x)\n",
        "    print(f\"x after dropout: {x.size()}\")\n",
        "    x = self.linear2(x) # Pass x to the second linear layer\n",
        "    print(f\"x after 2nd linear layer: {x.size()}\")\n",
        "    return x\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "    self.attention = MultiHeadAttention(d_model = d_model, num_heads = num_heads)\n",
        "    self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "    self.dropout1 = nn.Dropout(p = drop_prob)\n",
        "    self.ffn = PositionWiseFeedForward(d_model = d_model, hidden = ffn_hidden, drop_prob = drop_prob)\n",
        "    self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "    self.dropout2 = nn.Dropout(p = drop_prob)\n",
        "\n",
        "  def forward(self, x):\n",
        "    residual_x = x\n",
        "    print(\"\\n------- ATTENTION 1 ------\\n\")\n",
        "    x = self.attention(x, mask = None)\n",
        "    print(\"\\n------- DROPOUT 1 ------\\n\")\n",
        "    x = self.dropout1(x)\n",
        "    print(\"\\n------- ADD AND LAYER NORMALIZATION 1 ------\\n\")\n",
        "    x = self.norm1(x + residual_x)\n",
        "    residual_x = x\n",
        "    print(\"\\n------- ATTENTION 2 ------\\n\")\n",
        "    x = self.ffn(x)\n",
        "    print(\"\\n------- DROPOUT 2 ------\\n\")\n",
        "    x = self.dropout2(x)\n",
        "    print(\"\\b------- ADD AND LAYER NORMALIZATION 2 ------\\n\")\n",
        "    x = self.norm2(x + residual_x)\n",
        "    return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(*[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob) for _ in range(num_layers)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layers(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "NZFsfQRw11VL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 512\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "batch_size = 30\n",
        "max_sequence_length = 200\n",
        "ffn_hidden = 2048\n",
        "num_layers = 5"
      ],
      "metadata": {
        "id": "5ewq8ld94O2d"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)"
      ],
      "metadata": {
        "id": "Mb39iiQi4Ozv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRPcq0PK7HHb",
        "outputId": "02692bc7-d48b-4c08-c5e6-18f7ea4b8d89"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoder(\n",
              "  (layers): Sequential(\n",
              "    (0): EncoderLayer(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (ffn): PositionWiseFeedForward(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (relu): ReLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (norm2): LayerNormalization()\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): EncoderLayer(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (ffn): PositionWiseFeedForward(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (relu): ReLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (norm2): LayerNormalization()\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): EncoderLayer(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (ffn): PositionWiseFeedForward(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (relu): ReLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (norm2): LayerNormalization()\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): EncoderLayer(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (ffn): PositionWiseFeedForward(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (relu): ReLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (norm2): LayerNormalization()\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): EncoderLayer(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (ffn): PositionWiseFeedForward(\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (relu): ReLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (norm2): LayerNormalization()\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn( (batch_size, max_sequence_length, d_model) )"
      ],
      "metadata": {
        "id": "uBKE75Sm7HjY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb4QbZkP7OR4",
        "outputId": "11c0d9bf-f971-4213-c89e-823f5cc500c6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 200, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = encoder(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QAaz_Sn7PDI",
        "outputId": "ff9a7992-ac60-436e-84b4-7adc8445e76e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------- ATTENTION 1 ------\n",
            "\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size(): torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "\n",
            "------- DROPOUT 1 ------\n",
            "\n",
            "\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "\n",
            "Mean (torch.Size([30, 200, 1])): \n",
            "tensor([[[-0.0282],\n",
            "         [ 0.0046],\n",
            "         [ 0.0076],\n",
            "         ...,\n",
            "         [-0.0310],\n",
            "         [-0.0049],\n",
            "         [-0.0136]],\n",
            "\n",
            "        [[-0.0664],\n",
            "         [ 0.0753],\n",
            "         [ 0.0017],\n",
            "         ...,\n",
            "         [-0.0628],\n",
            "         [-0.0981],\n",
            "         [-0.0116]],\n",
            "\n",
            "        [[ 0.0435],\n",
            "         [ 0.0307],\n",
            "         [-0.1063],\n",
            "         ...,\n",
            "         [ 0.0218],\n",
            "         [ 0.0691],\n",
            "         [ 0.0286]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.0663],\n",
            "         [ 0.0417],\n",
            "         [ 0.0040],\n",
            "         ...,\n",
            "         [-0.0157],\n",
            "         [-0.0089],\n",
            "         [ 0.0064]],\n",
            "\n",
            "        [[-0.0822],\n",
            "         [-0.0574],\n",
            "         [-0.0570],\n",
            "         ...,\n",
            "         [-0.0826],\n",
            "         [-0.0473],\n",
            "         [-0.0160]],\n",
            "\n",
            "        [[ 0.0684],\n",
            "         [-0.0322],\n",
            "         [ 0.0310],\n",
            "         ...,\n",
            "         [-0.0547],\n",
            "         [-0.0966],\n",
            "         [ 0.0111]]], grad_fn=<MeanBackward1>)\n",
            "Standard Deviation (torch.Size([30, 200, 1])): \n",
            "tensor([[[0.9781],\n",
            "         [0.9991],\n",
            "         [1.0404],\n",
            "         ...,\n",
            "         [0.9869],\n",
            "         [0.9986],\n",
            "         [1.0340]],\n",
            "\n",
            "        [[0.9906],\n",
            "         [1.0021],\n",
            "         [1.0135],\n",
            "         ...,\n",
            "         [1.0095],\n",
            "         [0.9602],\n",
            "         [1.0319]],\n",
            "\n",
            "        [[0.9730],\n",
            "         [1.0163],\n",
            "         [0.9912],\n",
            "         ...,\n",
            "         [1.0216],\n",
            "         [0.9925],\n",
            "         [0.9913]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.0055],\n",
            "         [0.9803],\n",
            "         [0.9483],\n",
            "         ...,\n",
            "         [1.0157],\n",
            "         [1.0062],\n",
            "         [0.9606]],\n",
            "\n",
            "        [[0.9967],\n",
            "         [1.0502],\n",
            "         [1.0038],\n",
            "         ...,\n",
            "         [0.9857],\n",
            "         [0.9871],\n",
            "         [0.9458]],\n",
            "\n",
            "        [[1.0597],\n",
            "         [0.9692],\n",
            "         [0.9483],\n",
            "         ...,\n",
            "         [1.0061],\n",
            "         [1.0482],\n",
            "         [1.0266]]], grad_fn=<SqrtBackward0>)\n",
            "y (torch.Size([30, 200, 512])): \n",
            "tensor([[[ 7.9200e-01,  2.9774e-01,  7.8366e-01,  ..., -1.0627e+00,\n",
            "          -4.1754e-01,  5.2645e-01],\n",
            "         [ 1.2073e+00, -2.8141e-01,  2.7505e-01,  ..., -2.2964e-01,\n",
            "           1.6390e+00,  1.9528e-01],\n",
            "         [-1.1117e-01,  3.4561e-01, -3.7904e-01,  ..., -6.2822e-01,\n",
            "           4.4161e-01, -1.0922e+00],\n",
            "         ...,\n",
            "         [ 1.6217e+00,  2.1972e+00, -5.7889e-01,  ..., -1.1837e+00,\n",
            "           1.0892e+00, -5.6869e-02],\n",
            "         [ 1.1444e+00, -1.0437e-01,  1.7217e+00,  ..., -2.3614e+00,\n",
            "          -2.8843e-02,  5.4142e-01],\n",
            "         [ 5.6637e-01, -2.8337e+00,  7.6396e-01,  ..., -4.6440e-01,\n",
            "           1.1278e-01,  2.7697e+00]],\n",
            "\n",
            "        [[-8.3953e-01, -1.3791e+00, -1.6822e+00,  ...,  7.9452e-01,\n",
            "          -4.1549e-01, -8.9180e-01],\n",
            "         [ 1.1947e+00,  1.9628e+00,  2.8349e+00,  ..., -2.9842e-02,\n",
            "          -1.4035e+00,  2.7913e-01],\n",
            "         [ 8.2665e-01, -7.5309e-01, -1.2652e+00,  ...,  2.6741e-01,\n",
            "           1.3955e+00, -1.7734e+00],\n",
            "         ...,\n",
            "         [-1.4848e+00,  4.6044e-01, -1.6907e+00,  ..., -5.8216e-01,\n",
            "          -2.0602e+00, -4.0711e-01],\n",
            "         [-1.3327e-01, -1.7562e+00,  3.4957e-02,  ..., -2.8604e-01,\n",
            "           1.3302e+00, -1.3567e+00],\n",
            "         [ 1.0422e+00,  2.0296e+00, -8.7252e-01,  ...,  2.4946e-01,\n",
            "           2.1079e+00, -1.0171e+00]],\n",
            "\n",
            "        [[-7.7496e-02,  7.9203e-01,  3.6889e-01,  ...,  1.9047e-01,\n",
            "           1.3181e+00, -5.3158e-01],\n",
            "         [-4.1132e-01, -1.1126e+00, -1.8982e-02,  ..., -8.7463e-01,\n",
            "          -8.5133e-01, -1.1996e+00],\n",
            "         [-9.1418e-01, -1.0300e-01, -5.5250e-01,  ..., -5.0672e-01,\n",
            "          -2.5073e-01,  2.9885e+00],\n",
            "         ...,\n",
            "         [-7.1838e-01, -1.4227e+00,  4.2446e-01,  ...,  3.6818e-01,\n",
            "          -3.8113e-02, -5.3495e-01],\n",
            "         [ 4.7949e-01,  1.2208e+00,  1.8908e+00,  ...,  4.9948e-01,\n",
            "           3.4583e-01,  1.7097e+00],\n",
            "         [-2.5985e-01, -1.8623e+00, -5.9106e-01,  ...,  5.5517e-02,\n",
            "          -7.4992e-01,  1.8078e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-7.1925e-01,  6.2163e-01, -5.7393e-01,  ...,  1.1031e+00,\n",
            "           4.2504e-01,  1.0346e-03],\n",
            "         [-1.8672e+00, -3.3330e-02, -1.4879e+00,  ...,  4.6345e-01,\n",
            "          -1.7932e+00, -1.9231e-01],\n",
            "         [-3.5465e-01, -1.2793e+00,  9.3706e-01,  ...,  1.4942e+00,\n",
            "          -3.2652e-01,  4.0908e-01],\n",
            "         ...,\n",
            "         [ 2.8104e-01, -1.3605e+00,  1.1565e+00,  ..., -1.5216e+00,\n",
            "           1.3123e+00,  5.8202e-01],\n",
            "         [-1.3060e+00,  3.7754e-01, -1.5508e+00,  ...,  1.5348e+00,\n",
            "          -1.0912e+00, -2.1637e-01],\n",
            "         [ 6.9074e-02,  5.3937e-01,  1.5172e+00,  ...,  4.5240e-01,\n",
            "           1.2840e+00, -2.4310e+00]],\n",
            "\n",
            "        [[ 1.0115e+00, -1.2767e+00,  5.0461e-01,  ..., -1.1471e+00,\n",
            "          -1.3168e+00, -3.7205e-01],\n",
            "         [ 1.3500e+00,  3.6104e-01,  1.1037e+00,  ...,  2.0097e+00,\n",
            "          -7.5870e-01,  7.7960e-01],\n",
            "         [ 1.5859e+00,  1.8071e-01, -2.3537e-01,  ..., -1.1595e-01,\n",
            "           3.7920e-01, -2.5591e+00],\n",
            "         ...,\n",
            "         [-7.9824e-02,  9.3562e-01,  8.2534e-01,  ...,  1.3091e+00,\n",
            "           6.5118e-03, -2.8408e-01],\n",
            "         [-1.9569e-01,  2.0221e+00, -1.9530e+00,  ...,  3.5048e-01,\n",
            "           6.2714e-01, -9.9103e-01],\n",
            "         [-3.5866e-02, -8.8272e-01, -3.1869e-01,  ..., -2.2077e+00,\n",
            "           1.1879e-01,  7.5126e-01]],\n",
            "\n",
            "        [[ 3.0634e-01,  1.4577e+00,  5.4716e-01,  ..., -2.0197e+00,\n",
            "           2.4008e-01,  8.0996e-01],\n",
            "         [ 3.6630e-01,  5.1077e-01,  7.3363e-01,  ...,  1.0365e+00,\n",
            "          -1.2688e-01,  6.8442e-02],\n",
            "         [ 2.4287e-02, -2.3207e+00, -1.7485e+00,  ..., -1.1670e+00,\n",
            "          -9.9886e-01, -1.1334e+00],\n",
            "         ...,\n",
            "         [ 2.7812e-01,  5.9505e-01, -3.9512e-01,  ...,  3.6481e-02,\n",
            "          -1.3456e-01, -5.6918e-01],\n",
            "         [-9.5106e-01,  2.5769e-01, -1.6382e+00,  ..., -6.9157e-02,\n",
            "          -1.2513e-01,  7.1787e-01],\n",
            "         [ 8.2283e-01,  9.4702e-01, -1.2889e+00,  ...,  8.2799e-02,\n",
            "          -1.7177e-01,  8.8705e-01]]], grad_fn=<DivBackward0>)\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "Out: torch.Size([30, 200, 512])\n",
            "\n",
            "------- ATTENTION 2 ------\n",
            "\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "\n",
            "------- DROPOUT 2 ------\n",
            "\n",
            "\b------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "\n",
            "Mean (torch.Size([30, 200, 1])): \n",
            "tensor([[[0.9930],\n",
            "         [1.0248],\n",
            "         [1.0017],\n",
            "         ...,\n",
            "         [0.9789],\n",
            "         [1.0045],\n",
            "         [0.9968]],\n",
            "\n",
            "        [[1.0154],\n",
            "         [1.0111],\n",
            "         [1.0066],\n",
            "         ...,\n",
            "         [1.0262],\n",
            "         [1.0088],\n",
            "         [0.9828]],\n",
            "\n",
            "        [[1.0018],\n",
            "         [1.0044],\n",
            "         [1.0175],\n",
            "         ...,\n",
            "         [0.9906],\n",
            "         [1.0003],\n",
            "         [0.9973]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.9818],\n",
            "         [1.0031],\n",
            "         [0.9969],\n",
            "         ...,\n",
            "         [1.0196],\n",
            "         [1.0072],\n",
            "         [1.0047]],\n",
            "\n",
            "        [[0.9988],\n",
            "         [1.0046],\n",
            "         [1.0018],\n",
            "         ...,\n",
            "         [1.0031],\n",
            "         [1.0163],\n",
            "         [0.9849]],\n",
            "\n",
            "        [[1.0017],\n",
            "         [0.9966],\n",
            "         [0.9951],\n",
            "         ...,\n",
            "         [1.0008],\n",
            "         [1.0139],\n",
            "         [0.9961]]], grad_fn=<MeanBackward1>)\n",
            "Standard Deviation (torch.Size([30, 200, 1])): \n",
            "tensor([[[1.0976],\n",
            "         [1.0697],\n",
            "         [1.0756],\n",
            "         ...,\n",
            "         [1.0583],\n",
            "         [1.0677],\n",
            "         [1.0259]],\n",
            "\n",
            "        [[1.0823],\n",
            "         [1.0807],\n",
            "         [1.0625],\n",
            "         ...,\n",
            "         [1.0779],\n",
            "         [1.0524],\n",
            "         [1.0324]],\n",
            "\n",
            "        [[1.0775],\n",
            "         [1.0624],\n",
            "         [1.0415],\n",
            "         ...,\n",
            "         [1.0624],\n",
            "         [1.0771],\n",
            "         [1.0721]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.0805],\n",
            "         [1.0800],\n",
            "         [1.0748],\n",
            "         ...,\n",
            "         [1.1103],\n",
            "         [1.0837],\n",
            "         [1.0577]],\n",
            "\n",
            "        [[1.0773],\n",
            "         [1.0456],\n",
            "         [1.0624],\n",
            "         ...,\n",
            "         [1.0791],\n",
            "         [1.0636],\n",
            "         [1.0521]],\n",
            "\n",
            "        [[1.0472],\n",
            "         [1.0876],\n",
            "         [1.0369],\n",
            "         ...,\n",
            "         [1.0872],\n",
            "         [1.0572],\n",
            "         [1.0682]]], grad_fn=<SqrtBackward0>)\n",
            "y (torch.Size([30, 200, 512])): \n",
            "tensor([[[ 9.3786e-01,  7.2562e-01,  5.0073e-01,  ..., -8.9269e-01,\n",
            "          -6.9743e-01,  6.6296e-01],\n",
            "         [ 1.1055e+00,  4.5957e-01,  1.5653e-01,  ..., -4.8864e-02,\n",
            "           1.5758e+00, -4.2793e-01],\n",
            "         [-3.6246e-01,  4.7850e-01, -4.3549e-01,  ..., -5.0645e-01,\n",
            "           9.0823e-02, -1.2811e+00],\n",
            "         ...,\n",
            "         [ 1.5213e+00,  2.5453e+00, -1.1935e+00,  ..., -1.2186e+00,\n",
            "           4.4772e-01,  1.7898e-01],\n",
            "         [ 1.0676e+00,  4.7635e-01,  1.8835e+00,  ..., -2.5434e+00,\n",
            "           6.4379e-02, -8.6841e-02],\n",
            "         [ 8.6462e-01, -2.2623e+00,  9.2306e-01,  ..., -4.5279e-01,\n",
            "          -1.6251e-01,  2.4967e+00]],\n",
            "\n",
            "        [[-7.8993e-01, -1.0517e+00, -1.3283e+00,  ...,  4.3925e-01,\n",
            "          -6.3814e-01, -7.6605e-01],\n",
            "         [ 1.5259e+00,  2.6590e+00,  2.4541e+00,  ..., -8.6665e-02,\n",
            "          -1.6019e+00,  5.7166e-02],\n",
            "         [ 9.1133e-01,  2.4476e-01, -1.4509e+00,  ...,  2.0039e-01,\n",
            "           1.6463e+00, -2.1417e+00],\n",
            "         ...,\n",
            "         [-1.3733e+00,  9.1931e-01, -1.6238e+00,  ..., -6.7419e-01,\n",
            "          -1.9357e+00, -2.7104e-01],\n",
            "         [-5.8233e-01, -1.1888e+00, -5.8955e-02,  ..., -1.1668e-01,\n",
            "           1.1005e+00, -1.3223e+00],\n",
            "         [ 1.0168e+00,  1.9826e+00, -5.9637e-01,  ...,  2.5828e-01,\n",
            "           2.2602e+00, -1.4312e+00]],\n",
            "\n",
            "        [[-7.9237e-03,  8.7161e-01,  6.9473e-02,  ...,  4.6353e-01,\n",
            "           1.1546e+00, -4.5997e-01],\n",
            "         [-5.1024e-01, -6.8064e-01,  2.4690e-01,  ..., -1.0193e+00,\n",
            "          -1.2862e+00, -1.8466e+00],\n",
            "         [-8.9455e-01,  1.9283e-01, -9.5679e-01,  ..., -6.7558e-02,\n",
            "          -4.3409e-01,  2.7814e+00],\n",
            "         ...,\n",
            "         [-6.6734e-01, -1.3303e+00,  1.7928e-01,  ...,  6.1857e-01,\n",
            "           2.7004e-02, -7.2824e-01],\n",
            "         [ 1.3531e+00,  1.3262e+00,  1.7241e+00,  ...,  2.9695e-01,\n",
            "           4.6282e-02,  1.3284e+00],\n",
            "         [ 6.3894e-02, -1.4176e+00, -7.5559e-01,  ...,  1.5172e-01,\n",
            "          -1.1004e+00, -3.3058e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-6.4886e-01,  1.3385e+00, -7.1754e-01,  ...,  1.0233e+00,\n",
            "           3.6956e-01,  1.6755e-01],\n",
            "         [-1.7592e+00, -5.7752e-04, -1.7867e+00,  ...,  7.3619e-01,\n",
            "          -1.8325e+00, -6.2727e-01],\n",
            "         [-3.2708e-01, -1.2667e+00,  3.8093e-01,  ...,  1.4421e+00,\n",
            "          -3.0091e-01,  3.5051e-01],\n",
            "         ...,\n",
            "         [ 2.3551e-01, -1.5070e+00,  9.9326e-01,  ..., -1.5363e+00,\n",
            "           6.4267e-01, -5.7696e-02],\n",
            "         [-9.0973e-01,  5.8903e-01, -2.0967e+00,  ...,  1.1566e+00,\n",
            "          -1.3735e+00, -5.6094e-01],\n",
            "         [-4.5197e-01,  1.1410e+00,  1.3001e+00,  ...,  3.8024e-01,\n",
            "           1.1486e+00, -2.5710e+00]],\n",
            "\n",
            "        [[ 1.0330e+00, -1.1840e+00, -1.8408e-01,  ..., -1.2996e+00,\n",
            "          -1.7894e+00, -7.4954e-01],\n",
            "         [ 1.8336e+00,  7.7772e-01,  6.0957e-01,  ...,  1.7821e+00,\n",
            "          -9.8393e-01,  1.0496e+00],\n",
            "         [ 1.5750e+00,  7.1008e-01, -4.1477e-01,  ..., -7.6138e-02,\n",
            "           4.1827e-01, -2.3033e+00],\n",
            "         ...,\n",
            "         [-1.1535e-01,  1.0424e+00,  7.6963e-01,  ...,  1.3474e+00,\n",
            "          -5.0017e-01, -5.7721e-01],\n",
            "         [-1.2807e-01,  2.4371e+00, -1.8515e+00,  ...,  3.1421e-01,\n",
            "           1.7653e-02, -8.8316e-01],\n",
            "         [-3.0091e-01, -1.0714e-01, -5.7103e-01,  ..., -2.4228e+00,\n",
            "           5.3108e-02,  5.9950e-01]],\n",
            "\n",
            "        [[ 7.3596e-01,  1.7599e+00,  4.1890e-01,  ..., -1.8450e+00,\n",
            "           1.6253e-01,  2.3165e-01],\n",
            "         [ 8.3859e-01,  7.5832e-01,  5.2383e-01,  ...,  8.2789e-01,\n",
            "          -5.5024e-01,  2.0084e-01],\n",
            "         [ 2.8134e-02, -1.7540e+00, -1.8981e+00,  ..., -8.6693e-01,\n",
            "          -1.0645e+00, -1.0809e+00],\n",
            "         ...,\n",
            "         [ 2.5503e-01,  7.4145e-01, -5.7353e-01,  ..., -1.6357e-01,\n",
            "          -2.7331e-01, -4.3903e-01],\n",
            "         [-9.1273e-01,  6.1669e-01, -1.9261e+00,  ..., -7.8555e-02,\n",
            "          -2.6864e-01,  4.9194e-01],\n",
            "         [ 8.5311e-01,  8.9019e-01, -1.2202e+00,  ...,  2.1510e-01,\n",
            "          -5.2801e-01,  8.3405e-01]]], grad_fn=<DivBackward0>)\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "Out: torch.Size([30, 200, 512])\n",
            "\n",
            "------- ATTENTION 1 ------\n",
            "\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size(): torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "\n",
            "------- DROPOUT 1 ------\n",
            "\n",
            "\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "\n",
            "Mean (torch.Size([30, 200, 1])): \n",
            "tensor([[[0.9758],\n",
            "         [0.9705],\n",
            "         [0.9741],\n",
            "         ...,\n",
            "         [0.9956],\n",
            "         [0.9914],\n",
            "         [0.9865]],\n",
            "\n",
            "        [[0.9815],\n",
            "         [0.9761],\n",
            "         [0.9740],\n",
            "         ...,\n",
            "         [0.9907],\n",
            "         [1.0055],\n",
            "         [0.9884]],\n",
            "\n",
            "        [[0.9761],\n",
            "         [0.9706],\n",
            "         [0.9759],\n",
            "         ...,\n",
            "         [0.9942],\n",
            "         [0.9908],\n",
            "         [0.9967]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.9716],\n",
            "         [0.9712],\n",
            "         [0.9702],\n",
            "         ...,\n",
            "         [0.9917],\n",
            "         [0.9998],\n",
            "         [0.9889]],\n",
            "\n",
            "        [[0.9683],\n",
            "         [0.9752],\n",
            "         [0.9707],\n",
            "         ...,\n",
            "         [0.9886],\n",
            "         [0.9853],\n",
            "         [0.9911]],\n",
            "\n",
            "        [[0.9695],\n",
            "         [0.9788],\n",
            "         [0.9740],\n",
            "         ...,\n",
            "         [0.9901],\n",
            "         [0.9880],\n",
            "         [0.9942]]], grad_fn=<MeanBackward1>)\n",
            "Standard Deviation (torch.Size([30, 200, 1])): \n",
            "tensor([[[1.0574],\n",
            "         [1.0435],\n",
            "         [1.0645],\n",
            "         ...,\n",
            "         [1.0825],\n",
            "         [1.0623],\n",
            "         [1.0582]],\n",
            "\n",
            "        [[1.0646],\n",
            "         [1.0542],\n",
            "         [1.0773],\n",
            "         ...,\n",
            "         [1.0800],\n",
            "         [1.0861],\n",
            "         [1.0623]],\n",
            "\n",
            "        [[1.0482],\n",
            "         [1.0668],\n",
            "         [1.0830],\n",
            "         ...,\n",
            "         [1.0572],\n",
            "         [1.0373],\n",
            "         [1.0514]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.0383],\n",
            "         [1.0458],\n",
            "         [1.0678],\n",
            "         ...,\n",
            "         [1.0755],\n",
            "         [1.0635],\n",
            "         [1.0678]],\n",
            "\n",
            "        [[1.0468],\n",
            "         [1.0491],\n",
            "         [1.0905],\n",
            "         ...,\n",
            "         [1.0529],\n",
            "         [1.0335],\n",
            "         [1.0684]],\n",
            "\n",
            "        [[1.0742],\n",
            "         [1.0759],\n",
            "         [1.0669],\n",
            "         ...,\n",
            "         [1.0735],\n",
            "         [1.0792],\n",
            "         [1.0633]]], grad_fn=<SqrtBackward0>)\n",
            "y (torch.Size([30, 200, 512])): \n",
            "tensor([[[ 0.9099,  0.7760,  0.6690,  ..., -1.0541, -0.6367,  0.4097],\n",
            "         [ 0.9160,  0.4687,  0.3598,  ..., -0.0185,  2.7905, -0.6246],\n",
            "         [-0.4719,  0.5399, -0.2117,  ..., -0.7091,  1.3575, -1.4259],\n",
            "         ...,\n",
            "         [ 1.2746,  2.4946, -1.2236,  ..., -1.2115,  0.4603,  0.1694],\n",
            "         [ 0.8740,  0.4565,  1.6470,  ..., -2.4898,  0.1089, -0.1676],\n",
            "         [ 0.6950, -1.9878,  0.7516,  ..., -0.5161, -0.1194,  2.3721]],\n",
            "\n",
            "        [[-0.8786, -0.9093, -1.0201,  ...,  0.1020,  0.6725, -0.9332],\n",
            "         [ 1.3191,  2.5449,  2.5381,  ..., -0.3796, -0.2248, -0.1514],\n",
            "         [ 0.8700,  0.3007, -1.1133,  ..., -0.1139,  2.7999, -2.1881],\n",
            "         ...,\n",
            "         [-1.4119,  0.8598, -1.6663,  ..., -0.7194, -1.7539, -0.2423],\n",
            "         [-0.6878, -1.0996, -0.2079,  ..., -0.2182,  1.0430, -1.3278],\n",
            "         [ 0.8222,  1.9632, -0.6989,  ...,  0.1481,  2.1657, -1.4319]],\n",
            "\n",
            "        [[-0.1707,  1.0042,  0.2810,  ...,  0.1428,  2.3581, -0.6487],\n",
            "         [-0.4507, -0.6104,  0.4340,  ..., -1.2319,  0.0449, -1.9242],\n",
            "         [-0.9922,  0.3403, -0.6716,  ..., -0.3262,  0.8195,  2.3455],\n",
            "         ...,\n",
            "         [-0.7677, -1.1942,  0.0080,  ...,  0.4589,  0.0310, -0.7455],\n",
            "         [ 1.1690,  1.3402,  1.4874,  ...,  0.1854,  0.0677,  1.2118],\n",
            "         [-0.0688, -1.2913, -0.8972,  ...,  0.1475, -1.0146, -0.3720]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.8026,  1.3164, -0.4917,  ...,  0.7191,  1.6625, -0.0366],\n",
            "         [-1.6545,  0.0965, -1.4896,  ...,  0.4503, -0.4390, -0.7843],\n",
            "         [-0.2784, -1.1037,  0.5698,  ...,  1.0852,  0.9932,  0.1572],\n",
            "         ...,\n",
            "         [ 0.0808, -1.3348,  0.9313,  ..., -1.5100,  0.6147, -0.1253],\n",
            "         [-0.9952,  0.6270, -2.1313,  ...,  1.0014, -1.2954, -0.5964],\n",
            "         [-0.5543,  1.0790,  1.0494,  ...,  0.2909,  1.1009, -2.4528]],\n",
            "\n",
            "        [[ 0.8450, -1.0743, -0.1456,  ..., -1.5188, -0.4633, -0.9119],\n",
            "         [ 1.5989,  0.8046,  0.6047,  ...,  1.4037, -0.9142,  0.8060],\n",
            "         [ 1.3053,  0.7249, -0.2509,  ..., -0.3293,  1.5805, -2.3328],\n",
            "         ...,\n",
            "         [-0.2487,  1.0511,  0.5509,  ...,  1.2071, -0.4642, -0.6273],\n",
            "         [-0.2427,  2.4208, -1.9798,  ...,  0.2451,  0.0850, -0.9214],\n",
            "         [-0.4059, -0.0467, -0.7243,  ..., -2.3581,  0.1052,  0.4973]],\n",
            "\n",
            "        [[ 0.7135,  1.7348,  0.4184,  ..., -2.0104,  1.4243,  0.2441],\n",
            "         [ 0.6080,  0.7921,  0.6915,  ...,  0.7891,  0.7277,  0.2064],\n",
            "         [-0.1372, -1.6197, -1.5815,  ..., -1.1110,  0.2688, -1.2184],\n",
            "         ...,\n",
            "         [ 0.2468,  0.7615, -0.6287,  ..., -0.2592, -0.1699, -0.3997],\n",
            "         [-0.9631,  0.5826, -1.8911,  ..., -0.1668, -0.1736,  0.3859],\n",
            "         [ 0.6891,  0.8902, -1.2602,  ...,  0.0964, -0.4198,  0.7108]]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "Out: torch.Size([30, 200, 512])\n",
            "\n",
            "------- ATTENTION 2 ------\n",
            "\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "\n",
            "------- DROPOUT 2 ------\n",
            "\n",
            "\b------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "\n",
            "Mean (torch.Size([30, 200, 1])): \n",
            "tensor([[[0.9845],\n",
            "         [1.0037],\n",
            "         [1.0067],\n",
            "         ...,\n",
            "         [1.0088],\n",
            "         [0.9954],\n",
            "         [1.0044]],\n",
            "\n",
            "        [[1.0042],\n",
            "         [1.0090],\n",
            "         [1.0028],\n",
            "         ...,\n",
            "         [1.0123],\n",
            "         [1.0128],\n",
            "         [0.9932]],\n",
            "\n",
            "        [[0.9935],\n",
            "         [1.0176],\n",
            "         [1.0406],\n",
            "         ...,\n",
            "         [1.0011],\n",
            "         [1.0118],\n",
            "         [0.9981]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.9794],\n",
            "         [1.0163],\n",
            "         [0.9889],\n",
            "         ...,\n",
            "         [1.0102],\n",
            "         [1.0115],\n",
            "         [0.9983]],\n",
            "\n",
            "        [[1.0022],\n",
            "         [1.0072],\n",
            "         [1.0021],\n",
            "         ...,\n",
            "         [1.0061],\n",
            "         [1.0115],\n",
            "         [1.0034]],\n",
            "\n",
            "        [[0.9978],\n",
            "         [1.0128],\n",
            "         [1.0221],\n",
            "         ...,\n",
            "         [0.9889],\n",
            "         [0.9698],\n",
            "         [0.9922]]], grad_fn=<MeanBackward1>)\n",
            "Standard Deviation (torch.Size([30, 200, 1])): \n",
            "tensor([[[1.0565],\n",
            "         [1.0613],\n",
            "         [1.0796],\n",
            "         ...,\n",
            "         [1.0882],\n",
            "         [1.0719],\n",
            "         [1.0751]],\n",
            "\n",
            "        [[1.0798],\n",
            "         [1.0544],\n",
            "         [1.0440],\n",
            "         ...,\n",
            "         [1.0451],\n",
            "         [1.0537],\n",
            "         [1.0522]],\n",
            "\n",
            "        [[1.0512],\n",
            "         [1.0940],\n",
            "         [1.0243],\n",
            "         ...,\n",
            "         [1.0604],\n",
            "         [1.0646],\n",
            "         [1.0658]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.0493],\n",
            "         [1.0753],\n",
            "         [1.0502],\n",
            "         ...,\n",
            "         [1.0541],\n",
            "         [1.0825],\n",
            "         [1.0221]],\n",
            "\n",
            "        [[1.0765],\n",
            "         [1.0708],\n",
            "         [1.0845],\n",
            "         ...,\n",
            "         [1.0709],\n",
            "         [1.0601],\n",
            "         [1.0640]],\n",
            "\n",
            "        [[1.0817],\n",
            "         [1.0764],\n",
            "         [1.0885],\n",
            "         ...,\n",
            "         [1.1107],\n",
            "         [1.0489],\n",
            "         [1.0491]]], grad_fn=<SqrtBackward0>)\n",
            "y (torch.Size([30, 200, 512])): \n",
            "tensor([[[ 0.6186,  0.6201,  1.4269,  ..., -0.7022, -0.8538,  0.4151],\n",
            "         [ 0.8764,  0.4381,  0.7862,  ..., -0.0209,  2.6258, -0.1505],\n",
            "         [-0.7484,  0.0743,  0.0302,  ..., -0.6630,  1.5029, -1.2181],\n",
            "         ...,\n",
            "         [ 0.9188,  1.6120, -0.7950,  ..., -0.7704,  0.2388,  0.1292],\n",
            "         [ 0.7756, -0.4268,  2.0534,  ..., -2.3185,  0.3921,  0.5265],\n",
            "         [ 0.5378, -2.5477,  1.3270,  ..., -0.3897, -0.5558,  2.2723]],\n",
            "\n",
            "        [[-0.8184, -1.4361, -0.4894,  ...,  0.2215,  0.5934, -0.5605],\n",
            "         [ 1.1900,  1.3448,  2.6232,  ..., -0.1991, -0.0481, -0.5007],\n",
            "         [ 0.6400,  0.2853, -0.3500,  ...,  0.4288,  2.4659, -2.0986],\n",
            "         ...,\n",
            "         [-1.3348,  0.3808, -0.8653,  ..., -0.4806, -1.6900,  0.0454],\n",
            "         [-0.6649, -1.7257,  0.1574,  ...,  0.2431,  0.6348, -0.7022],\n",
            "         [ 0.7878,  1.2797, -0.0745,  ...,  0.3465,  1.8336, -0.9409]],\n",
            "\n",
            "        [[ 0.0136,  0.3095,  0.2735,  ..., -0.0104,  2.0336, -0.4548],\n",
            "         [-0.4281, -0.9467,  1.2392,  ..., -1.0552,  0.1446, -1.6916],\n",
            "         [-1.4185, -0.4584, -0.4813,  ...,  0.0306,  0.5219,  2.5120],\n",
            "         ...,\n",
            "         [-0.9406, -2.1263,  1.1625,  ...,  0.5257, -0.0544, -0.7042],\n",
            "         [ 1.1612,  0.9676,  2.2088,  ...,  0.1630, -0.0840,  1.2296],\n",
            "         [-0.1911, -1.3119, -0.2601,  ...,  0.0795, -0.9982, -0.5902]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.9904,  1.0529,  0.2759,  ...,  0.7183,  1.1465, -0.0152],\n",
            "         [-1.8369, -0.0260, -1.0814,  ...,  0.9857, -0.3718, -0.7887],\n",
            "         [-0.2545, -1.5606,  0.7840,  ...,  1.2516,  1.0901,  0.4110],\n",
            "         ...,\n",
            "         [-0.2602, -1.7486,  1.5393,  ..., -1.2250,  0.3355, -0.3936],\n",
            "         [-0.9270,  0.2770, -1.4860,  ...,  1.4596, -1.2211, -0.2596],\n",
            "         [-0.1115,  0.5894,  1.3092,  ...,  0.2874,  0.9393, -2.2197]],\n",
            "\n",
            "        [[ 0.9512, -1.3946,  0.3213,  ..., -0.6997, -0.5329, -0.5866],\n",
            "         [ 1.4866,  0.4024,  0.8223,  ...,  1.3042, -1.4848,  0.4788],\n",
            "         [ 1.0826,  0.5307,  0.5306,  ..., -0.0612,  1.4086, -2.4011],\n",
            "         ...,\n",
            "         [-0.4462,  0.6403,  1.0313,  ...,  1.2740, -0.3419, -0.6602],\n",
            "         [-0.5056,  1.8353, -1.2363,  ...,  0.2151, -0.2496, -0.3738],\n",
            "         [-0.4015, -0.3894, -0.6840,  ..., -2.0441, -0.4341,  0.5681]],\n",
            "\n",
            "        [[ 0.1124,  1.3175,  1.1156,  ..., -1.8565,  1.1103,  0.4812],\n",
            "         [ 0.6052,  0.5066,  0.8390,  ...,  0.8577,  0.6749,  0.2697],\n",
            "         [-0.2759, -2.0020, -1.4732,  ..., -0.3081,  0.0709, -1.1396],\n",
            "         ...,\n",
            "         [ 0.2322,  0.2512, -0.1116,  ...,  0.3387, -0.6348, -0.6334],\n",
            "         [-1.1477, -0.0562, -1.7743,  ...,  0.0631, -0.0990,  0.2836],\n",
            "         [ 0.9343,  0.6334, -0.7209,  ...,  0.5016, -0.7783,  0.9480]]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "Out: torch.Size([30, 200, 512])\n",
            "\n",
            "------- ATTENTION 1 ------\n",
            "\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size(): torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "\n",
            "------- DROPOUT 1 ------\n",
            "\n",
            "\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "\n",
            "Mean (torch.Size([30, 200, 1])): \n",
            "tensor([[[0.9994],\n",
            "         [0.9954],\n",
            "         [0.9989],\n",
            "         ...,\n",
            "         [0.9915],\n",
            "         [0.9923],\n",
            "         [0.9869]],\n",
            "\n",
            "        [[0.9931],\n",
            "         [1.0006],\n",
            "         [0.9967],\n",
            "         ...,\n",
            "         [0.9890],\n",
            "         [0.9889],\n",
            "         [0.9885]],\n",
            "\n",
            "        [[1.0073],\n",
            "         [0.9986],\n",
            "         [1.0013],\n",
            "         ...,\n",
            "         [0.9931],\n",
            "         [0.9847],\n",
            "         [0.9875]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.9986],\n",
            "         [0.9975],\n",
            "         [1.0055],\n",
            "         ...,\n",
            "         [0.9910],\n",
            "         [0.9874],\n",
            "         [0.9890]],\n",
            "\n",
            "        [[1.0017],\n",
            "         [1.0009],\n",
            "         [0.9972],\n",
            "         ...,\n",
            "         [0.9874],\n",
            "         [0.9958],\n",
            "         [0.9835]],\n",
            "\n",
            "        [[0.9957],\n",
            "         [0.9989],\n",
            "         [1.0044],\n",
            "         ...,\n",
            "         [0.9838],\n",
            "         [0.9892],\n",
            "         [0.9884]]], grad_fn=<MeanBackward1>)\n",
            "Standard Deviation (torch.Size([30, 200, 1])): \n",
            "tensor([[[1.0443],\n",
            "         [1.0706],\n",
            "         [1.0663],\n",
            "         ...,\n",
            "         [1.0330],\n",
            "         [1.0663],\n",
            "         [1.0717]],\n",
            "\n",
            "        [[1.0769],\n",
            "         [1.0702],\n",
            "         [1.0614],\n",
            "         ...,\n",
            "         [1.0475],\n",
            "         [1.0435],\n",
            "         [1.0663]],\n",
            "\n",
            "        [[1.0810],\n",
            "         [1.0482],\n",
            "         [1.0556],\n",
            "         ...,\n",
            "         [1.0856],\n",
            "         [1.0724],\n",
            "         [1.0674]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.0816],\n",
            "         [1.0566],\n",
            "         [1.0550],\n",
            "         ...,\n",
            "         [1.0747],\n",
            "         [1.0762],\n",
            "         [1.0665]],\n",
            "\n",
            "        [[1.0386],\n",
            "         [1.0678],\n",
            "         [1.0239],\n",
            "         ...,\n",
            "         [1.0660],\n",
            "         [1.0699],\n",
            "         [1.0462]],\n",
            "\n",
            "        [[1.0408],\n",
            "         [1.0518],\n",
            "         [1.0435],\n",
            "         ...,\n",
            "         [1.0410],\n",
            "         [1.0891],\n",
            "         [1.0541]]], grad_fn=<SqrtBackward0>)\n",
            "y (torch.Size([30, 200, 512])): \n",
            "tensor([[[ 3.6339e-01,  5.9429e-01,  9.3320e-01,  ..., -2.0401e-01,\n",
            "          -6.2116e-01,  1.0702e-01],\n",
            "         [ 8.2287e-01,  1.7894e-01,  3.0191e-01,  ...,  4.3102e-01,\n",
            "           2.6503e+00, -4.1197e-01],\n",
            "         [-9.1610e-01, -1.5020e-01, -3.9107e-01,  ..., -1.4809e-01,\n",
            "           1.6001e+00, -1.4239e+00],\n",
            "         ...,\n",
            "         [ 8.8526e-01,  1.9083e+00, -8.7691e-01,  ..., -1.0492e+00,\n",
            "           2.0102e-02, -7.8626e-02],\n",
            "         [ 7.1770e-01, -5.0271e-02,  1.9330e+00,  ..., -2.1672e+00,\n",
            "           1.8476e-01,  2.9444e-01],\n",
            "         [ 5.0752e-01, -2.0361e+00,  1.1726e+00,  ..., -6.4461e-01,\n",
            "          -6.9913e-01,  1.9322e+00]],\n",
            "\n",
            "        [[-1.0111e+00, -1.3271e+00, -8.2526e-01,  ...,  6.6774e-01,\n",
            "           6.9940e-01, -7.9394e-01],\n",
            "         [ 8.5794e-01,  1.0793e+00,  2.0486e+00,  ...,  2.8708e-01,\n",
            "           7.9406e-02, -7.4166e-01],\n",
            "         [ 3.2500e-01,  9.8157e-02, -7.2546e-01,  ...,  8.8560e-01,\n",
            "           2.4531e+00, -2.2383e+00],\n",
            "         ...,\n",
            "         [-1.3194e+00,  3.7409e-01, -8.1552e-01,  ..., -7.6899e-01,\n",
            "          -1.8381e+00, -2.2812e-01],\n",
            "         [-6.6373e-01, -1.3285e+00,  1.6151e-01,  ...,  2.4365e-01,\n",
            "           3.8330e-01, -9.4643e-01],\n",
            "         [ 7.0488e-01,  1.5262e+00, -1.1388e-01,  ...,  1.2445e-02,\n",
            "           1.5019e+00, -1.1456e+00]],\n",
            "\n",
            "        [[-2.5444e-01,  5.8530e-02,  2.4625e-01,  ...,  4.1888e-01,\n",
            "           2.0150e+00, -7.1107e-01],\n",
            "         [-6.7520e-01, -9.0179e-01,  7.5177e-01,  ..., -5.4010e-01,\n",
            "           2.9062e-01, -1.9218e+00],\n",
            "         [-1.6004e+00, -6.4728e-01, -8.8684e-01,  ...,  4.7942e-01,\n",
            "           6.5264e-01,  2.0712e+00],\n",
            "         ...,\n",
            "         [-8.8616e-01, -1.6579e+00,  1.0359e+00,  ...,  4.9060e-01,\n",
            "          -2.8594e-01, -9.0120e-01],\n",
            "         [ 1.0709e+00,  1.2186e+00,  2.0505e+00,  ..., -1.1397e-01,\n",
            "          -3.1358e-01,  9.1080e-01],\n",
            "         [-1.7572e-01, -9.2258e-01, -2.7328e-01,  ..., -1.9098e-01,\n",
            "          -1.1746e+00, -7.8789e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.1473e+00,  7.1554e-01, -1.1440e-01,  ...,  1.1156e+00,\n",
            "           1.2637e+00, -3.0458e-01],\n",
            "         [-1.9916e+00, -2.7936e-01, -1.4019e+00,  ...,  1.3865e+00,\n",
            "          -1.2762e-01, -1.0364e+00],\n",
            "         [-4.7986e-01, -1.4844e+00,  3.5841e-01,  ...,  1.6517e+00,\n",
            "           1.2627e+00,  6.8878e-02],\n",
            "         ...,\n",
            "         [-2.5077e-01, -1.3395e+00,  1.4407e+00,  ..., -1.4090e+00,\n",
            "           3.6065e-02, -6.1665e-01],\n",
            "         [-8.7641e-01,  5.5460e-01, -1.4023e+00,  ...,  1.0928e+00,\n",
            "          -1.3973e+00, -4.9377e-01],\n",
            "         [-1.1748e-01,  8.4145e-01,  1.1857e+00,  ...,  2.1188e-03,\n",
            "           8.9105e-01, -2.3205e+00]],\n",
            "\n",
            "        [[ 6.6220e-01, -1.5492e+00, -1.1109e-01,  ..., -2.0780e-01,\n",
            "          -3.6266e-01, -9.0166e-01],\n",
            "         [ 1.3914e+00,  1.6077e-01,  3.8587e-01,  ...,  1.6599e+00,\n",
            "          -1.2345e+00,  4.4761e-01],\n",
            "         [ 7.9404e-01,  3.0108e-01,  1.3056e-01,  ...,  4.2350e-01,\n",
            "           1.5258e+00, -2.6759e+00],\n",
            "         ...,\n",
            "         [-4.0669e-01,  9.0861e-01,  9.3167e-01,  ...,  1.2070e+00,\n",
            "          -3.0887e-01, -8.7106e-01],\n",
            "         [-5.1303e-01,  2.0164e+00, -1.2032e+00,  ..., -6.5015e-02,\n",
            "          -4.8585e-01, -6.1376e-01],\n",
            "         [-4.1287e-01, -5.7339e-02, -7.0997e-01,  ..., -2.2152e+00,\n",
            "          -6.7561e-01,  2.8779e-01]],\n",
            "\n",
            "        [[-1.4803e-01,  1.0766e+00,  6.9157e-01,  ..., -1.3289e+00,\n",
            "           1.2382e+00,  1.6336e-01],\n",
            "         [ 3.2333e-01,  2.8146e-01,  4.1829e-01,  ...,  1.2722e+00,\n",
            "           6.4267e-01, -2.6683e-02],\n",
            "         [-5.2053e-01, -1.9229e+00, -1.8137e+00,  ...,  1.4809e-01,\n",
            "           2.2463e-01, -1.3790e+00],\n",
            "         ...,\n",
            "         [ 2.5076e-01,  5.4280e-01, -1.4139e-01,  ...,  3.7554e-02,\n",
            "          -8.4382e-01, -8.1209e-01],\n",
            "         [-1.0250e+00,  2.4856e-01, -1.6534e+00,  ..., -2.0958e-01,\n",
            "          -3.1390e-01,  5.3743e-02],\n",
            "         [ 9.2216e-01,  9.0182e-01, -7.3575e-01,  ...,  1.9244e-01,\n",
            "          -9.6554e-01,  6.8825e-01]]], grad_fn=<DivBackward0>)\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "Out: torch.Size([30, 200, 512])\n",
            "\n",
            "------- ATTENTION 2 ------\n",
            "\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "\n",
            "------- DROPOUT 2 ------\n",
            "\n",
            "\b------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "\n",
            "Mean (torch.Size([30, 200, 1])): \n",
            "tensor([[[1.0132],\n",
            "         [1.0034],\n",
            "         [1.0121],\n",
            "         ...,\n",
            "         [1.0104],\n",
            "         [0.9987],\n",
            "         [0.9850]],\n",
            "\n",
            "        [[1.0006],\n",
            "         [1.0183],\n",
            "         [1.0225],\n",
            "         ...,\n",
            "         [0.9943],\n",
            "         [0.9886],\n",
            "         [1.0005]],\n",
            "\n",
            "        [[1.0128],\n",
            "         [1.0065],\n",
            "         [1.0166],\n",
            "         ...,\n",
            "         [1.0064],\n",
            "         [0.9818],\n",
            "         [1.0003]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.0000],\n",
            "         [1.0198],\n",
            "         [1.0256],\n",
            "         ...,\n",
            "         [1.0056],\n",
            "         [0.9944],\n",
            "         [0.9965]],\n",
            "\n",
            "        [[1.0087],\n",
            "         [1.0190],\n",
            "         [1.0240],\n",
            "         ...,\n",
            "         [0.9914],\n",
            "         [0.9994],\n",
            "         [1.0055]],\n",
            "\n",
            "        [[1.0284],\n",
            "         [0.9984],\n",
            "         [1.0163],\n",
            "         ...,\n",
            "         [1.0200],\n",
            "         [1.0256],\n",
            "         [0.9893]]], grad_fn=<MeanBackward1>)\n",
            "Standard Deviation (torch.Size([30, 200, 1])): \n",
            "tensor([[[1.0649],\n",
            "         [1.0797],\n",
            "         [1.0622],\n",
            "         ...,\n",
            "         [1.0728],\n",
            "         [1.0802],\n",
            "         [1.0453]],\n",
            "\n",
            "        [[1.0845],\n",
            "         [1.1006],\n",
            "         [1.0701],\n",
            "         ...,\n",
            "         [1.1023],\n",
            "         [1.0789],\n",
            "         [1.0705]],\n",
            "\n",
            "        [[1.0707],\n",
            "         [1.0645],\n",
            "         [1.0278],\n",
            "         ...,\n",
            "         [1.0487],\n",
            "         [1.0547],\n",
            "         [1.0533]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.0813],\n",
            "         [1.0728],\n",
            "         [1.0643],\n",
            "         ...,\n",
            "         [1.0832],\n",
            "         [1.0588],\n",
            "         [1.0767]],\n",
            "\n",
            "        [[1.0686],\n",
            "         [1.0725],\n",
            "         [1.0574],\n",
            "         ...,\n",
            "         [1.0586],\n",
            "         [1.0466],\n",
            "         [1.0571]],\n",
            "\n",
            "        [[1.0465],\n",
            "         [1.0774],\n",
            "         [1.0830],\n",
            "         ...,\n",
            "         [1.0545],\n",
            "         [1.0666],\n",
            "         [1.0636]]], grad_fn=<SqrtBackward0>)\n",
            "y (torch.Size([30, 200, 512])): \n",
            "tensor([[[ 0.6220,  0.7966,  0.8494,  ..., -0.2040, -0.5152, -0.0413],\n",
            "         [ 0.8445,  0.5171,  0.0385,  ..., -0.1819,  2.4315, -0.3847],\n",
            "         [-0.1353, -0.1255, -0.3389,  ..., -0.1508,  1.0781, -1.1048],\n",
            "         ...,\n",
            "         [ 0.8411,  1.7691, -0.4885,  ..., -0.8015, -0.3394, -0.0532],\n",
            "         [ 0.3479, -0.0428,  2.3432,  ..., -1.9425,  0.1722,  0.4970],\n",
            "         [ 0.4318, -1.8454,  1.1361,  ..., -0.9549, -1.2865,  2.1130]],\n",
            "\n",
            "        [[-0.9480, -0.7664, -0.3134,  ...,  0.2954,  0.4198, -0.7520],\n",
            "         [ 0.8391,  1.2977,  1.9929,  ..., -0.1836, -0.0963, -0.3193],\n",
            "         [ 0.1481,  0.3268, -0.4939,  ...,  0.5139,  2.3068, -2.1835],\n",
            "         ...,\n",
            "         [-1.1009,  0.4917, -0.3219,  ..., -0.6924, -1.9818, -0.1949],\n",
            "         [-0.6947, -1.2631,  0.5173,  ...,  0.4275, -0.2818, -0.5363],\n",
            "         [ 0.5451,  1.6478, -0.3766,  ..., -0.2695,  0.8768, -0.8776]],\n",
            "\n",
            "        [[-0.2236,  0.5538,  0.3816,  ...,  0.0656,  1.6764, -0.6116],\n",
            "         [-0.4954, -0.5529,  1.0252,  ..., -0.5776, -0.0316, -1.9237],\n",
            "         [-1.4902, -0.5458, -0.6166,  ...,  0.5922,  0.5886,  1.8723],\n",
            "         ...,\n",
            "         [-1.1581, -1.7805,  1.4152,  ...,  0.5325, -0.6091, -1.2084],\n",
            "         [ 0.4826,  1.1726,  1.9613,  ..., -0.0908, -0.4696,  0.8808],\n",
            "         [-0.1047, -0.3546,  0.0914,  ..., -0.5744, -1.4373, -0.6517]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.2962,  1.0145, -0.1803,  ...,  0.2734,  1.2876, -0.4301],\n",
            "         [-1.4913, -0.0623, -1.2427,  ...,  1.2573,  0.0077, -1.3225],\n",
            "         [-0.1778, -1.1176, -0.0089,  ...,  1.3827,  0.5560,  0.0278],\n",
            "         ...,\n",
            "         [-0.3297, -0.9728,  0.8763,  ..., -1.1516,  0.1590, -0.6849],\n",
            "         [-0.6741,  0.8097, -0.7935,  ...,  0.6084, -1.2821, -0.4405],\n",
            "         [-0.5863,  0.9759,  1.0943,  ...,  0.0903,  0.6995, -2.3511]],\n",
            "\n",
            "        [[ 0.6264, -1.6458,  0.0033,  ..., -0.5498, -0.8472, -1.0662],\n",
            "         [ 1.3846,  0.1322,  0.3218,  ...,  1.5629, -1.4283,  0.1183],\n",
            "         [ 0.9799,  0.4502,  0.1007,  ...,  0.2783,  1.2488, -3.0999],\n",
            "         ...,\n",
            "         [-0.3660,  1.0142,  0.9174,  ...,  1.2533, -0.8880, -0.8279],\n",
            "         [-0.4454,  1.9273, -0.8485,  ..., -0.3569, -0.8356, -0.9396],\n",
            "         [-0.2802,  0.2897, -0.0620,  ..., -2.1731, -0.6345, -0.1025]],\n",
            "\n",
            "        [[-0.4240,  1.1203,  0.8232,  ..., -1.6924,  1.4464, -0.1220],\n",
            "         [ 0.5486,  0.4437,  0.4214,  ...,  1.3428,  0.4333,  0.1587],\n",
            "         [-0.5695, -1.7906, -1.3120,  ...,  0.1217,  0.1924, -1.2884],\n",
            "         ...,\n",
            "         [ 0.4917,  0.6173,  0.3733,  ...,  0.0081, -1.0396, -0.3262],\n",
            "         [-0.8157,  0.1319, -0.8285,  ..., -0.2910, -0.4260, -0.2072],\n",
            "         [ 0.8720,  0.5264, -0.5236,  ...,  0.2827, -1.0728,  0.5326]]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "Out: torch.Size([30, 200, 512])\n",
            "\n",
            "------- ATTENTION 1 ------\n",
            "\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size(): torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "\n",
            "------- DROPOUT 1 ------\n",
            "\n",
            "\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "\n",
            "Mean (torch.Size([30, 200, 1])): \n",
            "tensor([[[1.0077],\n",
            "         [1.0034],\n",
            "         [1.0043],\n",
            "         ...,\n",
            "         [0.9965],\n",
            "         [0.9884],\n",
            "         [0.9897]],\n",
            "\n",
            "        [[1.0042],\n",
            "         [1.0171],\n",
            "         [1.0078],\n",
            "         ...,\n",
            "         [0.9919],\n",
            "         [0.9873],\n",
            "         [0.9985]],\n",
            "\n",
            "        [[1.0115],\n",
            "         [1.0171],\n",
            "         [1.0104],\n",
            "         ...,\n",
            "         [0.9901],\n",
            "         [0.9870],\n",
            "         [0.9884]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.0073],\n",
            "         [1.0043],\n",
            "         [1.0089],\n",
            "         ...,\n",
            "         [0.9978],\n",
            "         [0.9913],\n",
            "         [0.9962]],\n",
            "\n",
            "        [[1.0116],\n",
            "         [1.0150],\n",
            "         [1.0199],\n",
            "         ...,\n",
            "         [0.9848],\n",
            "         [0.9907],\n",
            "         [1.0007]],\n",
            "\n",
            "        [[1.0125],\n",
            "         [1.0048],\n",
            "         [1.0147],\n",
            "         ...,\n",
            "         [0.9930],\n",
            "         [0.9909],\n",
            "         [0.9978]]], grad_fn=<MeanBackward1>)\n",
            "Standard Deviation (torch.Size([30, 200, 1])): \n",
            "tensor([[[1.0817],\n",
            "         [1.0766],\n",
            "         [1.0759],\n",
            "         ...,\n",
            "         [1.0451],\n",
            "         [1.0435],\n",
            "         [1.0542]],\n",
            "\n",
            "        [[1.0871],\n",
            "         [1.0978],\n",
            "         [1.0791],\n",
            "         ...,\n",
            "         [1.0369],\n",
            "         [1.0281],\n",
            "         [1.0402]],\n",
            "\n",
            "        [[1.0930],\n",
            "         [1.1057],\n",
            "         [1.1093],\n",
            "         ...,\n",
            "         [1.0353],\n",
            "         [1.0381],\n",
            "         [1.0422]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.0885],\n",
            "         [1.1099],\n",
            "         [1.0841],\n",
            "         ...,\n",
            "         [1.0432],\n",
            "         [1.0573],\n",
            "         [1.0431]],\n",
            "\n",
            "        [[1.0932],\n",
            "         [1.1064],\n",
            "         [1.1059],\n",
            "         ...,\n",
            "         [1.0610],\n",
            "         [1.0330],\n",
            "         [1.0590]],\n",
            "\n",
            "        [[1.0684],\n",
            "         [1.1093],\n",
            "         [1.0888],\n",
            "         ...,\n",
            "         [1.0381],\n",
            "         [1.0387],\n",
            "         [1.0613]]], grad_fn=<SqrtBackward0>)\n",
            "y (torch.Size([30, 200, 512])): \n",
            "tensor([[[ 0.5514,  1.0632,  0.9155,  ...,  0.0412, -0.8700,  0.3721],\n",
            "         [ 0.7514,  0.8022,  0.1728,  ...,  0.0567,  1.8828,  0.0663],\n",
            "         [-0.1719,  0.1963, -0.1630,  ...,  0.0975,  0.6403, -0.5960],\n",
            "         ...,\n",
            "         [ 0.4709,  1.8580, -1.0202,  ..., -1.0611,  0.2493, -0.1547],\n",
            "         [-0.0070,  0.1392,  1.7035,  ..., -2.1370,  0.7443,  0.3741],\n",
            "         [ 0.0609, -1.5884,  0.5267,  ..., -1.1768, -0.6462,  1.9063]],\n",
            "\n",
            "        [[-0.8759, -0.3995, -0.1156,  ...,  0.2678,  0.0481, -0.2618],\n",
            "         [ 0.7177,  1.4812,  1.9685,  ...,  0.0646, -0.4308,  0.1062],\n",
            "         [ 0.1264,  0.6168, -0.2989,  ...,  0.7134,  1.7857, -1.6089],\n",
            "         ...,\n",
            "         [-1.0539,  0.6152, -0.8088,  ..., -0.9653, -1.3439, -0.2488],\n",
            "         [-1.0202, -1.0972, -0.0194,  ...,  0.1263,  0.3079, -0.5936],\n",
            "         [ 0.1899,  1.5855, -0.8916,  ..., -0.5922,  1.4111, -0.8422]],\n",
            "\n",
            "        [[-0.2452,  0.4961,  0.4915,  ...,  0.2948,  1.1574, -0.1682],\n",
            "         [-0.4811, -0.2429,  1.0570,  ..., -0.3181, -0.4172, -1.7552],\n",
            "         [-1.3730, -0.2135, -0.4197,  ...,  0.7572,  0.1460,  2.0776],\n",
            "         ...,\n",
            "         [-1.3985, -1.5806,  0.8142,  ...,  0.2010,  0.0064, -1.2253],\n",
            "         [ 0.1686,  1.2977,  1.3284,  ..., -0.4016,  0.1268,  0.7757],\n",
            "         [-0.4028, -0.1999, -0.4651,  ..., -0.8623, -0.8298, -0.6142]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.1976,  1.2451, -0.0603,  ...,  0.4638,  0.8075, -0.0053],\n",
            "         [-1.4117,  0.2724, -1.0131,  ...,  1.3406, -0.3523, -0.7812],\n",
            "         [-0.2267, -0.7150,  0.1025,  ...,  1.4846,  0.1320,  0.4423],\n",
            "         ...,\n",
            "         [-0.7407, -0.7908,  0.8422,  ..., -1.4584,  0.7295, -0.7484],\n",
            "         [-1.0395,  0.9065, -1.2146,  ...,  0.2346, -0.6372, -0.4084],\n",
            "         [-0.9758,  0.9392,  1.0527,  ..., -0.2359,  1.2564, -2.3656]],\n",
            "\n",
            "        [[ 0.5315, -1.2123,  0.1152,  ..., -0.2455, -1.1809, -0.5872],\n",
            "         [ 1.2106,  0.4091,  0.4003,  ...,  1.6822, -1.7078,  0.4887],\n",
            "         [ 0.8385,  0.6631,  0.1931,  ...,  0.4908,  0.7243, -2.4367],\n",
            "         ...,\n",
            "         [-0.6645,  1.1064,  0.8789,  ...,  1.1955, -0.2730, -0.8539],\n",
            "         [-0.7737,  1.9983, -1.3621,  ..., -0.6950, -0.2470, -1.0177],\n",
            "         [-0.6113,  0.4152, -0.0591,  ..., -2.3894, -0.0641, -0.1912]],\n",
            "\n",
            "        [[-0.4659,  1.3578,  0.8973,  ..., -1.3246,  0.9600,  0.2895],\n",
            "         [ 0.4471,  0.7117,  0.5238,  ...,  1.4878,  0.0321,  0.5384],\n",
            "         [-0.5809, -1.3347, -1.0845,  ...,  0.3727, -0.2103, -0.7960],\n",
            "         ...,\n",
            "         [ 0.0892,  0.7110, -0.1314,  ..., -0.3027, -0.4309, -0.4085],\n",
            "         [-1.1405,  0.2434, -1.2812,  ..., -0.5881,  0.1395, -0.2702],\n",
            "         [ 0.8237,  0.6048, -0.9819,  ..., -0.0425, -0.4722,  0.4119]]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "Out: torch.Size([30, 200, 512])\n",
            "\n",
            "------- ATTENTION 2 ------\n",
            "\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "\n",
            "------- DROPOUT 2 ------\n",
            "\n",
            "\b------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "\n",
            "Mean (torch.Size([30, 200, 1])): \n",
            "tensor([[[1.0058],\n",
            "         [0.9918],\n",
            "         [0.9930],\n",
            "         ...,\n",
            "         [0.9853],\n",
            "         [1.0127],\n",
            "         [0.9918]],\n",
            "\n",
            "        [[0.9890],\n",
            "         [0.9828],\n",
            "         [1.0033],\n",
            "         ...,\n",
            "         [1.0025],\n",
            "         [1.0029],\n",
            "         [0.9912]],\n",
            "\n",
            "        [[1.0118],\n",
            "         [1.0068],\n",
            "         [0.9756],\n",
            "         ...,\n",
            "         [0.9877],\n",
            "         [0.9873],\n",
            "         [0.9902]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.9947],\n",
            "         [0.9777],\n",
            "         [1.0029],\n",
            "         ...,\n",
            "         [0.9922],\n",
            "         [0.9965],\n",
            "         [1.0138]],\n",
            "\n",
            "        [[1.0050],\n",
            "         [0.9935],\n",
            "         [0.9910],\n",
            "         ...,\n",
            "         [0.9831],\n",
            "         [0.9931],\n",
            "         [1.0104]],\n",
            "\n",
            "        [[0.9927],\n",
            "         [0.9928],\n",
            "         [0.9711],\n",
            "         ...,\n",
            "         [0.9917],\n",
            "         [1.0084],\n",
            "         [0.9954]]], grad_fn=<MeanBackward1>)\n",
            "Standard Deviation (torch.Size([30, 200, 1])): \n",
            "tensor([[[1.0701],\n",
            "         [1.0839],\n",
            "         [1.0689],\n",
            "         ...,\n",
            "         [1.0498],\n",
            "         [1.0608],\n",
            "         [1.0753]],\n",
            "\n",
            "        [[1.0597],\n",
            "         [1.0706],\n",
            "         [1.0593],\n",
            "         ...,\n",
            "         [1.0603],\n",
            "         [1.0819],\n",
            "         [1.0433]],\n",
            "\n",
            "        [[1.0480],\n",
            "         [1.0365],\n",
            "         [1.0806],\n",
            "         ...,\n",
            "         [1.0688],\n",
            "         [1.0799],\n",
            "         [1.0669]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.0565],\n",
            "         [1.0900],\n",
            "         [1.0669],\n",
            "         ...,\n",
            "         [1.0657],\n",
            "         [1.0695],\n",
            "         [1.0614]],\n",
            "\n",
            "        [[1.0728],\n",
            "         [1.0777],\n",
            "         [1.0789],\n",
            "         ...,\n",
            "         [1.0396],\n",
            "         [1.0506],\n",
            "         [1.0739]],\n",
            "\n",
            "        [[1.0528],\n",
            "         [1.0616],\n",
            "         [1.0588],\n",
            "         ...,\n",
            "         [1.0898],\n",
            "         [1.0807],\n",
            "         [1.0702]]], grad_fn=<SqrtBackward0>)\n",
            "y (torch.Size([30, 200, 512])): \n",
            "tensor([[[ 2.9733e-01,  9.8814e-01,  7.7535e-01,  ...,  9.9104e-02,\n",
            "          -1.6044e+00,  2.1030e-01],\n",
            "         [ 5.1454e-01,  6.9193e-01,  3.2798e-01,  ..., -3.4162e-01,\n",
            "           1.1403e+00,  3.6608e-01],\n",
            "         [-3.7235e-01,  1.9019e-01,  2.1781e-01,  ..., -4.9418e-02,\n",
            "           5.6795e-04, -3.1195e-01],\n",
            "         ...,\n",
            "         [ 4.6260e-01,  1.6368e+00, -8.8069e-01,  ..., -9.9675e-01,\n",
            "          -1.9984e-01,  4.0612e-01],\n",
            "         [-8.1704e-01, -2.9717e-01,  1.7896e+00,  ..., -1.7434e+00,\n",
            "           5.0094e-01,  8.0396e-01],\n",
            "         [-4.3242e-01, -1.2726e+00,  2.9847e-01,  ..., -1.0867e+00,\n",
            "          -1.0216e+00,  2.3170e+00]],\n",
            "\n",
            "        [[-8.3368e-01, -1.7000e-01,  3.0703e-02,  ...,  2.6308e-01,\n",
            "           5.5710e-02,  6.8265e-02],\n",
            "         [ 4.0679e-02,  1.1641e+00,  2.2304e+00,  ..., -3.0261e-02,\n",
            "          -1.3274e+00,  1.0778e-01],\n",
            "         [-3.1696e-01,  2.1571e-01, -2.2127e-01,  ...,  5.2108e-01,\n",
            "           1.0576e+00, -1.0682e+00],\n",
            "         ...,\n",
            "         [-1.4192e+00,  4.6921e-01, -8.4812e-01,  ..., -1.5126e+00,\n",
            "          -1.8628e+00, -1.5260e-01],\n",
            "         [-1.6229e+00, -1.2079e+00,  1.9325e-01,  ...,  4.4817e-02,\n",
            "           1.5442e-01, -2.9874e-01],\n",
            "         [-4.4154e-01,  1.5282e+00, -1.1134e+00,  ..., -8.0788e-02,\n",
            "           8.9095e-01, -6.8530e-01]],\n",
            "\n",
            "        [[-5.5820e-01,  5.4509e-01,  7.2428e-01,  ...,  3.3485e-01,\n",
            "           3.7162e-01, -1.3826e-01],\n",
            "         [-3.5869e-01, -9.0625e-02,  1.2732e+00,  ..., -5.2476e-01,\n",
            "          -1.1275e+00, -1.4521e+00],\n",
            "         [-1.4625e+00, -1.5259e-01, -3.6583e-01,  ...,  9.4547e-01,\n",
            "          -5.3004e-01,  2.5686e+00],\n",
            "         ...,\n",
            "         [-1.8416e+00, -2.0113e+00,  1.0624e+00,  ...,  1.9960e-01,\n",
            "          -4.6606e-01, -1.1349e+00],\n",
            "         [ 1.9882e-02,  1.3352e+00,  1.4377e+00,  ...,  4.1155e-02,\n",
            "          -2.8081e-01,  1.3665e+00],\n",
            "         [-6.8328e-01, -2.4013e-01, -3.4490e-01,  ..., -7.9909e-01,\n",
            "          -9.1419e-01, -2.7180e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.5686e+00,  1.4017e+00, -9.1813e-02,  ...,  4.7311e-01,\n",
            "           7.6929e-01,  2.9005e-01],\n",
            "         [-1.3598e+00,  2.9324e-01, -8.1150e-01,  ...,  9.5475e-01,\n",
            "          -9.2389e-01, -3.9472e-01],\n",
            "         [-2.2960e-01, -1.0370e+00,  3.5193e-01,  ...,  1.2053e+00,\n",
            "          -7.1731e-01,  6.2916e-01],\n",
            "         ...,\n",
            "         [-9.7030e-01, -7.3318e-01,  1.1602e+00,  ..., -1.3612e+00,\n",
            "           1.9435e-01, -1.9385e-01],\n",
            "         [-1.3443e+00,  1.1858e+00, -1.1081e+00,  ...,  4.3797e-01,\n",
            "          -1.3929e+00, -1.1697e-01],\n",
            "         [-1.1613e+00,  7.3348e-01,  9.6474e-01,  ...,  3.5420e-01,\n",
            "           1.1707e+00, -2.0549e+00]],\n",
            "\n",
            "        [[ 2.5758e-02, -1.4172e+00,  1.1220e-01,  ..., -2.1786e-01,\n",
            "          -1.3481e+00, -4.7439e-01],\n",
            "         [ 5.2871e-01,  1.9162e-01,  3.0286e-01,  ...,  1.1710e+00,\n",
            "          -2.2545e+00,  8.7392e-01],\n",
            "         [ 6.1793e-01,  7.0434e-01,  4.2316e-02,  ...,  3.1258e-01,\n",
            "           3.9991e-01, -1.8632e+00],\n",
            "         ...,\n",
            "         [-1.1620e+00,  1.1756e+00,  1.0488e+00,  ...,  1.3646e+00,\n",
            "          -6.9348e-01, -6.3132e-01],\n",
            "         [-1.3620e+00,  1.7229e+00, -1.4126e+00,  ..., -4.5078e-01,\n",
            "          -6.4743e-01, -1.1937e+00],\n",
            "         [-8.6455e-01,  3.9898e-01,  1.0592e-01,  ..., -2.1103e+00,\n",
            "          -5.8037e-01,  4.4375e-01]],\n",
            "\n",
            "        [[-5.5966e-01,  1.0989e+00,  1.2392e+00,  ..., -1.3291e+00,\n",
            "           5.5219e-01,  5.4795e-01],\n",
            "         [ 2.8705e-01,  2.1238e-01,  7.9415e-01,  ...,  1.1112e+00,\n",
            "          -5.6430e-01,  8.1835e-01],\n",
            "         [-5.2138e-01, -1.2333e+00, -9.9695e-01,  ...,  5.5260e-03,\n",
            "          -9.3907e-01, -5.9799e-01],\n",
            "         ...,\n",
            "         [-8.2237e-02,  6.6001e-01, -2.5695e-01,  ..., -5.3656e-02,\n",
            "          -1.0558e+00, -1.6245e-02],\n",
            "         [-1.2221e+00,  1.9165e-01, -1.1933e+00,  ..., -6.6618e-01,\n",
            "          -4.5864e-01, -7.8732e-02],\n",
            "         [ 1.9910e-01,  4.7772e-01, -9.4049e-01,  ..., -8.3089e-02,\n",
            "          -9.0946e-01,  3.8920e-01]]], grad_fn=<DivBackward0>)\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "Out: torch.Size([30, 200, 512])\n",
            "\n",
            "------- ATTENTION 1 ------\n",
            "\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size(): torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "\n",
            "------- DROPOUT 1 ------\n",
            "\n",
            "\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "\n",
            "Mean (torch.Size([30, 200, 1])): \n",
            "tensor([[[1.0306],\n",
            "         [1.0358],\n",
            "         [1.0291],\n",
            "         ...,\n",
            "         [0.9887],\n",
            "         [0.9878],\n",
            "         [0.9901]],\n",
            "\n",
            "        [[1.0238],\n",
            "         [1.0293],\n",
            "         [1.0247],\n",
            "         ...,\n",
            "         [0.9740],\n",
            "         [0.9901],\n",
            "         [0.9726]],\n",
            "\n",
            "        [[1.0292],\n",
            "         [1.0306],\n",
            "         [1.0197],\n",
            "         ...,\n",
            "         [0.9780],\n",
            "         [0.9933],\n",
            "         [0.9927]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.0353],\n",
            "         [1.0328],\n",
            "         [1.0334],\n",
            "         ...,\n",
            "         [0.9841],\n",
            "         [0.9780],\n",
            "         [0.9727]],\n",
            "\n",
            "        [[1.0240],\n",
            "         [1.0248],\n",
            "         [1.0328],\n",
            "         ...,\n",
            "         [0.9808],\n",
            "         [0.9887],\n",
            "         [0.9972]],\n",
            "\n",
            "        [[1.0290],\n",
            "         [1.0334],\n",
            "         [1.0319],\n",
            "         ...,\n",
            "         [0.9779],\n",
            "         [0.9757],\n",
            "         [0.9717]]], grad_fn=<MeanBackward1>)\n",
            "Standard Deviation (torch.Size([30, 200, 1])): \n",
            "tensor([[[1.0706],\n",
            "         [1.0634],\n",
            "         [1.0464],\n",
            "         ...,\n",
            "         [1.0711],\n",
            "         [1.0809],\n",
            "         [1.0805]],\n",
            "\n",
            "        [[1.0585],\n",
            "         [1.0656],\n",
            "         [1.0726],\n",
            "         ...,\n",
            "         [1.0891],\n",
            "         [1.0935],\n",
            "         [1.0866]],\n",
            "\n",
            "        [[1.0677],\n",
            "         [1.0600],\n",
            "         [1.0816],\n",
            "         ...,\n",
            "         [1.1219],\n",
            "         [1.0996],\n",
            "         [1.0722]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.0782],\n",
            "         [1.0453],\n",
            "         [1.0608],\n",
            "         ...,\n",
            "         [1.0866],\n",
            "         [1.0763],\n",
            "         [1.1154]],\n",
            "\n",
            "        [[1.0711],\n",
            "         [1.0937],\n",
            "         [1.0572],\n",
            "         ...,\n",
            "         [1.0886],\n",
            "         [1.0845],\n",
            "         [1.0933]],\n",
            "\n",
            "        [[1.0631],\n",
            "         [1.0513],\n",
            "         [1.0784],\n",
            "         ...,\n",
            "         [1.0897],\n",
            "         [1.0693],\n",
            "         [1.0875]]], grad_fn=<SqrtBackward0>)\n",
            "y (torch.Size([30, 200, 512])): \n",
            "tensor([[[-0.1063,  0.5442,  0.7333,  ...,  0.7893, -1.3542, -0.3438],\n",
            "         [ 0.1091,  0.2527,  0.3138,  ...,  0.3769,  1.2006, -0.1746],\n",
            "         [-0.7443, -0.2161,  0.2156,  ...,  0.6677,  0.1318, -0.8302],\n",
            "         ...,\n",
            "         [-0.0867,  1.1629, -0.4169,  ..., -1.8342, -0.0171,  0.3642],\n",
            "         [-1.2830, -0.6411,  2.0779,  ..., -2.5077,  0.6362,  0.7205],\n",
            "         [-0.9186, -1.5467,  0.6831,  ..., -1.9006, -0.7697,  2.1325]],\n",
            "\n",
            "        [[-1.1417, -0.6119,  0.0896,  ...,  0.9560,  0.1663, -0.4557],\n",
            "         [-0.3198,  0.6568,  2.1483,  ...,  0.6874, -1.1391, -0.4244],\n",
            "         [-0.3185,  0.1781, -0.1579,  ...,  1.1957,  1.1022, -1.5249],\n",
            "         ...,\n",
            "         [-1.7835,  0.0933, -0.7548,  ..., -2.2617, -1.6864, -0.1311],\n",
            "         [-1.9787, -1.4696,  0.5654,  ..., -0.8548,  0.2900, -0.2681],\n",
            "         [-0.8879,  1.0780, -0.6089,  ..., -0.0491,  0.9446, -0.6288]],\n",
            "\n",
            "        [[-0.8682,  0.0552,  0.6812,  ...,  0.2863,  0.4309, -0.7066],\n",
            "         [-0.6904, -0.5450,  1.2036,  ...,  0.1928, -0.9753, -1.9318],\n",
            "         [-1.6649, -0.5928, -0.3330,  ...,  0.8559, -0.4320,  1.8451],\n",
            "         ...,\n",
            "         [-2.1302, -2.1158,  1.3423,  ..., -0.6770, -0.2557, -1.0496],\n",
            "         [-0.4798,  0.8734,  1.7103,  ..., -0.8426, -0.0905,  1.2045],\n",
            "         [-1.1574, -0.5671,  0.0583,  ..., -0.7384, -0.6985, -0.2921]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.7969,  1.2673, -0.1130,  ...,  1.1120,  0.7853, -0.2500],\n",
            "         [-1.6327, -0.2006, -0.8053,  ...,  1.6100, -0.8160, -0.9035],\n",
            "         [-0.5661, -1.4603,  0.3130,  ...,  1.8205, -0.5858,  0.0783],\n",
            "         ...,\n",
            "         [-0.8784, -1.0283,  1.4802,  ..., -1.2381,  0.3379, -0.2268],\n",
            "         [-1.7739,  0.7480, -0.6087,  ..., -0.4800, -1.1178, -0.1600],\n",
            "         [-1.5472,  0.3211,  1.2703,  ..., -0.5337,  1.2266, -1.8875]],\n",
            "\n",
            "        [[-0.3190, -1.7605,  0.1450,  ...,  0.4935, -1.1568, -0.9651],\n",
            "         [ 0.1428, -0.2526,  0.3143,  ...,  1.7440, -1.9811,  0.2943],\n",
            "         [ 0.2305,  0.2100,  0.0890,  ...,  0.9954,  0.4467, -1.7934],\n",
            "         ...,\n",
            "         [-1.6299,  0.7130,  1.3514,  ...,  0.4108, -0.4186, -0.5623],\n",
            "         [-1.8164,  1.2024, -0.9371,  ..., -1.2666, -0.3857, -1.1430],\n",
            "         [-0.7881, -0.0244,  0.4580,  ..., -2.7763, -0.3191,  0.3498]],\n",
            "\n",
            "        [[-0.8709,  0.6153,  1.1644,  ..., -0.5399,  0.6311, -0.0236],\n",
            "         [-0.0837, -0.2095,  0.7320,  ...,  1.7846, -0.4142,  0.2108],\n",
            "         [-0.8539, -1.5614, -0.9287,  ...,  0.6956, -0.7653, -1.0866],\n",
            "         ...,\n",
            "         [-0.0552,  0.2292,  0.1921,  ..., -0.9078, -0.8132, -0.0219],\n",
            "         [-1.6371, -0.2257, -0.6801,  ..., -1.4881, -0.2549, -0.0844],\n",
            "         [-0.3033,  0.0522, -0.4302,  ..., -0.9279, -0.6749,  0.3525]]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "Out: torch.Size([30, 200, 512])\n",
            "\n",
            "------- ATTENTION 2 ------\n",
            "\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "\n",
            "------- DROPOUT 2 ------\n",
            "\n",
            "\b------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "\n",
            "Mean (torch.Size([30, 200, 1])): \n",
            "tensor([[[0.9798],\n",
            "         [0.9946],\n",
            "         [0.9945],\n",
            "         ...,\n",
            "         [1.0108],\n",
            "         [1.0148],\n",
            "         [1.0098]],\n",
            "\n",
            "        [[0.9775],\n",
            "         [0.9935],\n",
            "         [0.9844],\n",
            "         ...,\n",
            "         [1.0123],\n",
            "         [1.0007],\n",
            "         [1.0122]],\n",
            "\n",
            "        [[0.9942],\n",
            "         [0.9932],\n",
            "         [0.9879],\n",
            "         ...,\n",
            "         [0.9990],\n",
            "         [0.9858],\n",
            "         [1.0006]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.9896],\n",
            "         [0.9929],\n",
            "         [0.9956],\n",
            "         ...,\n",
            "         [1.0084],\n",
            "         [0.9978],\n",
            "         [1.0067]],\n",
            "\n",
            "        [[0.9808],\n",
            "         [0.9665],\n",
            "         [1.0041],\n",
            "         ...,\n",
            "         [1.0057],\n",
            "         [1.0254],\n",
            "         [0.9949]],\n",
            "\n",
            "        [[0.9918],\n",
            "         [0.9892],\n",
            "         [0.9753],\n",
            "         ...,\n",
            "         [1.0047],\n",
            "         [1.0207],\n",
            "         [1.0031]]], grad_fn=<MeanBackward1>)\n",
            "Standard Deviation (torch.Size([30, 200, 1])): \n",
            "tensor([[[1.0688],\n",
            "         [1.0794],\n",
            "         [1.0500],\n",
            "         ...,\n",
            "         [1.0872],\n",
            "         [1.0830],\n",
            "         [1.0867]],\n",
            "\n",
            "        [[1.0566],\n",
            "         [1.0736],\n",
            "         [1.0691],\n",
            "         ...,\n",
            "         [1.0633],\n",
            "         [1.0665],\n",
            "         [1.0602]],\n",
            "\n",
            "        [[1.0403],\n",
            "         [1.0615],\n",
            "         [1.0589],\n",
            "         ...,\n",
            "         [1.0864],\n",
            "         [1.0428],\n",
            "         [1.0898]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.0596],\n",
            "         [1.0876],\n",
            "         [1.0703],\n",
            "         ...,\n",
            "         [1.0897],\n",
            "         [1.0761],\n",
            "         [1.0804]],\n",
            "\n",
            "        [[1.0849],\n",
            "         [1.0562],\n",
            "         [1.0622],\n",
            "         ...,\n",
            "         [1.0656],\n",
            "         [1.0603],\n",
            "         [1.0910]],\n",
            "\n",
            "        [[1.0682],\n",
            "         [1.0733],\n",
            "         [1.0620],\n",
            "         ...,\n",
            "         [1.0652],\n",
            "         [1.0853],\n",
            "         [1.0715]]], grad_fn=<SqrtBackward0>)\n",
            "y (torch.Size([30, 200, 512])): \n",
            "tensor([[[ 0.2278, -0.2183,  0.5806,  ...,  0.9557, -0.9447,  0.5017],\n",
            "         [ 0.4235, -0.3880,  0.0396,  ...,  0.5945,  1.5639, -0.1568],\n",
            "         [-0.6824, -0.7435, -0.1313,  ...,  1.1194,  0.2365, -0.7854],\n",
            "         ...,\n",
            "         [ 0.2925,  0.9098, -0.8876,  ..., -1.3247, -0.4584,  0.5207],\n",
            "         [-1.1269, -1.2907,  1.8112,  ..., -1.8156,  0.6461,  1.2389],\n",
            "         [-0.7347, -1.7381,  1.0379,  ..., -1.5387, -0.9011,  2.3173]],\n",
            "\n",
            "        [[-0.7381, -1.2290,  0.1514,  ...,  1.4015,  0.3835, -0.2084],\n",
            "         [ 0.0753,  0.1475,  1.6094,  ...,  1.0099, -0.9872, -0.3892],\n",
            "         [ 0.2596, -0.4428, -0.3976,  ...,  1.8700,  1.0972, -0.8398],\n",
            "         ...,\n",
            "         [-1.6819, -0.5091, -0.6266,  ..., -1.6582, -1.3556,  0.3586],\n",
            "         [-1.9918, -1.5600,  0.4213,  ..., -0.5388,  0.3560,  0.3679],\n",
            "         [-1.0002,  0.5561, -0.7591,  ...,  0.4795,  0.7449, -0.2655]],\n",
            "\n",
            "        [[-0.5445, -0.4072,  0.2145,  ...,  0.7208,  0.8675, -0.2406],\n",
            "         [-0.4016, -1.4398,  0.7886,  ...,  1.1784, -0.6977, -1.7016],\n",
            "         [-1.2971, -0.5484, -0.3953,  ...,  1.0346,  0.1505,  1.8874],\n",
            "         ...,\n",
            "         [-2.1661, -2.5476,  1.0879,  ..., -0.3418, -0.3358, -0.6228],\n",
            "         [ 0.2033,  0.1647,  1.9100,  ..., -0.4115, -0.0601,  1.4871],\n",
            "         [-1.1160, -1.1541,  0.1360,  ..., -0.0984, -0.7769,  0.0181]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.4246,  1.2058, -0.5663,  ...,  1.0593,  1.4528,  0.1266],\n",
            "         [-1.4172, -0.7298, -0.7339,  ...,  1.9181, -0.6087, -0.5084],\n",
            "         [-0.4953, -2.1418,  0.2966,  ...,  2.3378, -0.7229,  0.4896],\n",
            "         ...,\n",
            "         [-0.5768, -1.0454,  1.2179,  ..., -0.6458,  0.0394,  0.0268],\n",
            "         [-1.6675,  0.4038, -0.5227,  ..., -0.1117, -1.3158,  0.2123],\n",
            "         [-1.1003, -0.1913,  0.9141,  ..., -0.4860,  1.0167, -1.5303]],\n",
            "\n",
            "        [[-0.0987, -2.1429, -0.0212,  ...,  0.9805, -0.4055, -0.8718],\n",
            "         [ 0.0477, -0.5374, -0.2191,  ...,  2.0528, -1.5019,  0.8709],\n",
            "         [ 0.8376, -0.5737, -0.2748,  ...,  1.5815,  0.7147, -1.6218],\n",
            "         ...,\n",
            "         [-1.1715,  0.2241,  1.4279,  ...,  1.1265, -0.3392, -0.1283],\n",
            "         [-1.6709,  0.5856, -0.9648,  ..., -0.8773, -0.4891, -1.0339],\n",
            "         [-0.7446, -0.7491,  0.3099,  ..., -2.3572, -0.0470,  0.6802]],\n",
            "\n",
            "        [[-0.9158,  0.0755,  0.7533,  ..., -0.2138,  0.8080,  0.2314],\n",
            "         [ 0.2677, -0.9637,  0.5196,  ...,  1.7562, -0.2093,  0.8598],\n",
            "         [-0.3798, -2.0473, -0.8513,  ...,  1.1149, -0.6803, -0.9328],\n",
            "         ...,\n",
            "         [-0.2515, -0.3577,  0.0806,  ..., -0.8566, -0.6785,  0.4762],\n",
            "         [-1.8123, -0.5256, -0.6483,  ..., -1.1466, -0.3859,  0.3262],\n",
            "         [-0.5940, -0.6423, -0.1889,  ..., -0.8541, -0.5248,  0.3262]]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "Out: torch.Size([30, 200, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "summary(encoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjsxWb7G8D8x",
        "outputId": "f968d895-ddd0-4575-adaa-367c23e2fe99"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type:depth-idx)                        Param #\n",
              "======================================================================\n",
              "Encoder                                       --\n",
              "Sequential: 1-1                             --\n",
              "    EncoderLayer: 2-1                      --\n",
              "        MultiHeadAttention: 3-1           1,050,624\n",
              "        LayerNormalization: 3-2           1,024\n",
              "        Dropout: 3-3                      --\n",
              "        PositionWiseFeedForward: 3-4      2,099,712\n",
              "        LayerNormalization: 3-5           1,024\n",
              "        Dropout: 3-6                      --\n",
              "    EncoderLayer: 2-2                      --\n",
              "        MultiHeadAttention: 3-7           1,050,624\n",
              "        LayerNormalization: 3-8           1,024\n",
              "        Dropout: 3-9                      --\n",
              "        PositionWiseFeedForward: 3-10     2,099,712\n",
              "        LayerNormalization: 3-11          1,024\n",
              "        Dropout: 3-12                     --\n",
              "    EncoderLayer: 2-3                      --\n",
              "        MultiHeadAttention: 3-13          1,050,624\n",
              "        LayerNormalization: 3-14          1,024\n",
              "        Dropout: 3-15                     --\n",
              "        PositionWiseFeedForward: 3-16     2,099,712\n",
              "        LayerNormalization: 3-17          1,024\n",
              "        Dropout: 3-18                     --\n",
              "    EncoderLayer: 2-4                      --\n",
              "        MultiHeadAttention: 3-19          1,050,624\n",
              "        LayerNormalization: 3-20          1,024\n",
              "        Dropout: 3-21                     --\n",
              "        PositionWiseFeedForward: 3-22     2,099,712\n",
              "        LayerNormalization: 3-23          1,024\n",
              "        Dropout: 3-24                     --\n",
              "    EncoderLayer: 2-5                      --\n",
              "        MultiHeadAttention: 3-25          1,050,624\n",
              "        LayerNormalization: 3-26          1,024\n",
              "        Dropout: 3-27                     --\n",
              "        PositionWiseFeedForward: 3-28     2,099,712\n",
              "        LayerNormalization: 3-29          1,024\n",
              "        Dropout: 3-30                     --\n",
              "======================================================================\n",
              "Total params: 15,761,920\n",
              "Trainable params: 15,761,920\n",
              "Non-trainable params: 0\n",
              "======================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U0hFy7oW8LLd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}